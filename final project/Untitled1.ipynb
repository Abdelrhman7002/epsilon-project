{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf51a83-4bf3-4e58-98de-04c878eacdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 300}\n",
      "Test Accuracy: 82.12%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Feature Engineering\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch']\n",
    "data['IsAlone'] = (data['FamilySize'] == 0).astype(int)\n",
    "data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "data['Nickname'] = data['Name'].apply(lambda x:x.split()[1][:-1])\n",
    "\n",
    "\n",
    "# Define features and target variable\n",
    "X = data.drop(['Survived', 'Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_features = ['Sex', 'Embarked','Nickname']\n",
    "numerical_features = ['Age', 'Fare', 'FamilySize', 'Pclass', 'SibSp', 'Parch']\n",
    "\n",
    "# Preprocessing steps for each column type\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')), \n",
    "            ('scaler', StandardScaler())]), numerical_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Model pipeline\n",
    "model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning with GridSearch\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [5, 10, 15],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8305ac04-0db4-4fef-8e66-542f2b18addf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 83.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\myanaconda\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:07:29] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Feature Engineering\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch']\n",
    "data['IsAlone'] = (data['FamilySize'] == 0).astype(int)\n",
    "data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "\n",
    "# Simplify titles\n",
    "data['Title'] = data['Name'].apply(lambda x:x.split()[1][:-1])\n",
    "data['Title'] = data['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', \n",
    "                                       'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "data['Title'] = data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "data['Title'] = data['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Bin ages into categories (optional)\n",
    "data['AgeBin'] = pd.cut(data['Age'], bins=[0, 12, 18, 35, 60, 100], labels=['Child', 'Teen', 'Young Adult', 'Adult', 'Senior'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X = data.drop(['Survived', 'Name', 'Ticket', 'Cabin', 'PassengerId', 'Age'], axis=1)\n",
    "y = data['Survived']\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "categorical_features = ['Sex', 'Embarked', 'Title', 'AgeBin']\n",
    "numerical_features = ['Fare', 'FamilySize', 'Pclass', 'SibSp', 'Parch', 'IsAlone']\n",
    "\n",
    "# Preprocessing steps for each column type\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')), \n",
    "            ('scaler', StandardScaler())]), numerical_features),\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Define models\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10)\n",
    "gb_clf = GradientBoostingClassifier(random_state=42, n_estimators=200, max_depth=5)\n",
    "xgb_clf = XGBClassifier(random_state=42, n_estimators=200, max_depth=5, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Ensemble with Voting Classifier\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('rf', rf_clf), ('gb', gb_clf), ('xgb', xgb_clf)], voting='soft')\n",
    "\n",
    "# Model pipeline\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', ensemble_model)\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c59c50-8ee3-4fd6-b7d2-f4c46b894ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
